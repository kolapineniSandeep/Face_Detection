<!DOCTYPE html>
<html>
   <head>
      <meta charset="utf-8">
      <meta http-equiv="X-UA-Compatible" content="chrome=1">
      <title>Face Detection</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1">
      <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
      <link rel="stylesheet" href="./static/css/styling.css">
      <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
      <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>
      <!-- Add these JavaScript files from pico.js library -->
      <script src="./static/js/camvas.js"></script>
      <script src="./static/js/pico.js"></script>
      <script src="./static/js/lploc.js"></script>
      <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
      <script>
       $('#accessdenied').show();
         var initialized = false;
         var captured = false;
         	var img = new Image();
         	var ctx;
         function button_callback() {

         	var loader = document.getElementById("loader");
         	loader.style.display = "none";

         	/*
         		(0) check whether we're already running face detection
         	*/
         	if (initialized)
         		return; // if yes, then do not initialize everything again
         	/*
         		(1) initialize the pico.js face detector
         	*/
         	var update_memory = pico.instantiate_detection_memory(1); // we will use the detecions of the last 1 frame
         	var facefinder_classify_region = function (r, c, s, pixels, ldim) {return -1.0;};
         	var cascadeurl = 'https://raw.githubusercontent.com/nenadmarkus/pico/c2e81f9d23cc11d1a612fd21e4f9de0921a5d0d9/rnt/cascades/facefinder';
         	fetch(cascadeurl).then(function (response) {
         		response.arrayBuffer().then(function (buffer) {
         			var bytes = new Int8Array(buffer);
         			facefinder_classify_region = pico.unpack_cascade(bytes);
         			console.log('* facefinder loaded');
         		})
         	})
         	/*
         		(2) initialize the lploc.js library with a pupil localizer
         	*/
         	var do_puploc = function (r, c, s, nperturbs, pixels, nrows, ncols, ldim) {return [-1.0, -1.0];};
         	//var puplocurl = '../puploc.bin';
         	var puplocurl = 'https://f002.backblazeb2.com/file/tehnokv-www/posts/puploc-with-trees/demo/puploc.bin'
         	fetch(puplocurl).then(function (response) {
         		response.arrayBuffer().then(function (buffer) {
         			var bytes = new Int8Array(buffer);
         			do_puploc = lploc.unpack_localizer(bytes);
         			console.log('* puploc loaded');
         		})
         	})
         	/*
         		(3) get the drawing context on the canvas and define a function to transform an RGBA image to grayscale
         	*/
         	 ctx = document.getElementsByTagName('canvas')[0].getContext('2d');
         	function rgba_to_grayscale(rgba, nrows, ncols) {
         		var gray = new Uint8Array(nrows * ncols);
         		for (var r = 0; r < nrows; ++r)
         			for (var c = 0; c < ncols; ++c)
         				// gray = 0.2*red + 0.7*green + 0.1*blue
         				gray[r * ncols + c] = (2 * rgba[r * 4 * ncols + 4 * c + 0] + 7 * rgba[r * 4 * ncols + 4 * c + 1] + 1 * rgba[r * 4 * ncols + 4 * c + 2]) / 10;
         		return gray;
         	}
         	/*
         		(4) this function is called each time a video frame becomes available
         	*/
         	var processfn = function (video, dt) {
         		// render the video frame to the canvas element and extract RGBA pixel data
         		ctx.drawImage(video, 0, 0);
         		var rgba = ctx.getImageData(0, 0, 640, 480).data;
         		// prepare input to `run_cascade`
         		image = {
         			"pixels": rgba_to_grayscale(rgba, 480, 640),
         			"nrows": 480,
         			"ncols": 640,
         			"ldim": 640
         		}
         		params = {
         			"shiftfactor": 0.1, // move the detection window by 10% of its size
         			"minsize": 100,     // minimum size of a face
         			"maxsize": 1000,    // maximum size of a face
         			"scalefactor": 1.1  // for multiscale processing: resize the detection window by 10% when moving to the higher scale
         		}
         		// run the cascade over the frame and cluster the obtained detections
         		// dets is an array that contains (r, c, s, q) quadruplets
         		// (representing row, column, scale and detection score)
         		dets = pico.run_cascade(image, facefinder_classify_region, params);
         		dets = update_memory(dets);
         		dets = pico.cluster_detections(dets, 0.2); // set IoU threshold to 0.2
         		// draw detections
         		for (i = 0; i < dets.length; ++i) {
         			// check the detection score
         			// if it's above the threshold, draw it
         			// (the constant 50.0 is empirical: other cascades might require a different one)
         			if (dets[i][3] > 50.0) {
         				var r, c, s;
         				//
         				ctx.beginPath();
         				ctx.arc(dets[i][1], dets[i][0], dets[i][2] / 2, 0, 2 * Math.PI, false);
         				ctx.lineWidth = 5;
         				ctx.strokeStyle = 'green';
         				ctx.stroke();


         				// At this point, we already know that the human face is detected in webcam. So, We'll simply create an image from canvas that is displaying the webcam result in real-time.
         				var can = document.getElementsByTagName('canvas')[0]

         				img.src = can.toDataURL('image/jpeg', 1.0);


         				loader.style.display = "block";
         			}
         		}
         	}
         	/*
         		(5) instantiate camera handling (see https://github.com/cbrandolino/camvas)
         	*/
         	var mycamvas = new camvas(ctx, processfn);
         	/*
         		(6) it seems that everything went well
         	*/
         	initialized = true;
         }
          function postFile() {
        let formdata = new FormData();
        formdata.append("image", img.src);
        let xhr = new XMLHttpRequest();
        xhr.open('POST', 'http://localhost:5000/image', true);
        xhr.onload = function () {
            if (this.status === 200){

              alert(this.response);

            }
            else
                console.error(xhr);
        };
        xhr.send(formdata);
    }

      </script>
   </head>
   <body onload="button_callback()">
      <div class="topnav">
         <a class="active" href="#home">Face Detection System </a>
         <a href="/image-upload-view">Add New User</a>
         <a href="#news">View All Users</a>
         <a href="#contact">Check Failed Access</a>
         <a href="#about">About</a>
      </div>
      <div class="container-fluid">
         <div class="row content">
            <div class="col-sm-2 sidenav">
               <div class="loader" id="loader"> </div>
               <strong>please wait we are detecting </strong>

               <div class="alert alert-error" id="accessdenied">
  <span>
    <p>Looks like your face don't match!</p>
  </span>
</div>
            </div>
            <div class="col-sm-9">
               <center>
                  <canvas  width="640" height="480"></canvas>
               </center>
               <button type="submit" class="btn btn-success" onclick="postFile()">Check access</button>
               </form>
               <br><br>
            </div>
         </div>
      </div>
      <footer class="container-fluid">
         <p>All Copy rights owned by Lambton Pycharm Group</p>

      </footer>
   </body>
</html>